교재명: 텐서플로 2.0 프로그래밍, 위키북스, 김환희
예제코드: github.com/wikibook/tf2

# 뉴런
- 뉴런은 인공 신경망에서 기본적인 단위로, 입력값을 받아 가중치와 활성화 함수를 적용하여 출력값을 계산하는 수학적 연산을 수행하는 단일 처리 유닛
- 뇌의 생물학적 뉴런에서 영감을 받아 개발된 인공 신경망에서의 뉴런은 입력값을 받아 가중치와의 곱을 합산하고,
  그 결과에 활성화 함수를 적용하여 출력값을 계산하는 역할을 수행함
- 뉴런은 신경망의 기본 구성 요소이며, 여러 개의 뉴런이 서로 연결되어 네트워크를 형성함
- 인공 신경망에서의 뉴런은 입력값, 가중치, 활성화 함수, 출력값 등으로 구성되어 있으며, 
  이들이 조합되어 복잡한 입력-출력 관계를 모델링하고 예측하는 데 사용됨
- 뉴런은 가중치와 활성화 함수의 조합에 따라 다양한 종류의 신경망을 구성할 수 있으며, 신경망의 성능과 학습 능력에 영향을 미침

# 시그모이드 함수
- 로지스틱 함수
- 주어진 입력값(x)에 대해 0과 1 사이의 값을 반환하는 비선형 함수
- 주로 이진 분류 문제에서 출력값을 확률 형태로 표현할 때 사용
- 딥러닝에서는 활성화 함수로 사용됨

# 경사하강법
x = 입력값
y = 실제값
w = 가중치
b = 편향
output = 예측값
오차 = 실제값 - 예측값
학습률
=> 입력값이 0일 때 편향을 추가함 (입력값이 0이 아닌 경우에는 편향이 업데이트 되지 않음
				  but 필요에 따라 편향을 업데이트할 수도 있음)
=> 편향에 1을 곱하는 이유는 편향을 업데이트하는 학습률의 값을 조정하기 위함
=> 여기서 가장 중요한 파라미터는 가중치와 편향임 -> 가중치와 편향을 학습하기 위해 경사하강법을 사용한 것
=> 가중치와 편향은 모델의 학습을 통해 최적화되어 가설 함수가 입력 데이터를 잘 예측할 수 있도록 업데이트됨
=> 학습률은 가중치와 편향을 업데이트하는 양을 결정하는 파라미터로, 적절한 학습률을 선택하는 것이 모델의 학습 성능을 좌우함
=> 학습률이 너무 작으면 학습이 느리게 진행되고, 학습률이 너무 크면 발산하여 최적의 가중치와 편향을 찾지 못할 수 있음
=> 적절한 학습률을 설정하는 것이 중요함 -> 이 값은 사용자가 직접 설정할 수 있으며, 필요에 따라 조정되어야 함
=> 최적의 학습률은 문제에 따라 다를 수 있기 때문에 여러 가지 실험을 통해 찾아야 함

# 첫번째 신경망 네트워크 AND
- 첫번째 신경망 네트워크에서는 and연산을 수행하는 모델을 구현하는 것이 목적
- 입력값이 모두 True일 때만 True를 출력하는 연산 
 -> and연산은 두 개의 이진 입력을 받아 두 입력이 모두 True(1)일 때만 출력이 True(1)이 되고, 그 외의 경우에는 False(0)를 출력함
- and연산은 입력값이 두 개인 경우에만 사용함

# 두번째 신경망 네트워크 OR
- OR 연산은 입력값이 두 개인 경우에 사용하는 논리 연산자로, 
  두 개의 입력 중 하나라도 참(True)이면 출력이 참(True)이 되는 논리 연산

# 세번째 신경망 네트워크 XOR
- 두 개의 입력이 서로 다를 때만 출력이 참(True)이 되는 논리 연산
- 단층 신경망으로는 해결할 수 없는 비선형 문제 -> 적어도 두 개 이상의 은닉층을 가지는 다층 신경망 사용
- tf.keras -> 다층 신경망을 구성할 때 Sequential 클래스를 사용하여 각 층을 순차적으로 쌓아나가는 방식으로 모델을 구성함
- 문제 해결에 tf.keras가 필수적인 것은 아님 -> numpy 등을 사용하여 직접 신경망을 구현하는 것도 가능함
  -> 효율성 등을 고려하면 사용하는 것이 좋음
- 뉴런의 개수가 n개 -> 활성화 함수를 적용하여 출력하는 과정을 n번 반복
- 확률적 경사 하강법(SGD): 가중치와 편향을 업데이트하기 위한 최적화 알고리즘 중 하나
			   학습 데이터의 일부를 사용하여 매번 가중치와 편향을 업에이트하는 방식 (경사 하강법과 다름)
  => 더 빠르게 학습이 가능함 but 무작위성을 포함하므로 학습의 불안정성이 있을 수 있음
